{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kavishchaudhary1003/playground-s3-e5?scriptVersionId=119873045\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.model_selection import KFold, cross_val_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, make_scorer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, IsolationForest, StackingClassifier, RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn.model_selection import StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/playground-series-s3e5'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-09T14:53:15.202026Z","iopub.execute_input":"2023-02-09T14:53:15.20252Z","iopub.status.idle":"2023-02-09T14:53:15.810964Z","shell.execute_reply.started":"2023-02-09T14:53:15.202466Z","shell.execute_reply":"2023-02-09T14:53:15.809579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Page\nhttps://www.kaggle.com/competitions/playground-series-s3e5","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e5/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e5/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:07.826887Z","iopub.execute_input":"2023-02-09T14:54:07.827704Z","iopub.status.idle":"2023-02-09T14:54:07.849646Z","shell.execute_reply.started":"2023-02-09T14:54:07.827656Z","shell.execute_reply":"2023-02-09T14:54:07.848495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.duplicated().sum()\ntrain.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for null and duplicates\n","metadata":{}},{"cell_type":"code","source":"train.set_index('Id', inplace = True)\ntest.set_index('Id', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:11.688643Z","iopub.execute_input":"2023-02-09T14:54:11.68984Z","iopub.status.idle":"2023-02-09T14:54:11.69859Z","shell.execute_reply.started":"2023-02-09T14:54:11.689796Z","shell.execute_reply":"2023-02-09T14:54:11.697323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data description","metadata":{}},{"cell_type":"code","source":"corr = train.corr()\ncorr.style.background_gradient(cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coorelation heat map","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"If = IsolationForest()\nIf.fit(train)\ntrain['anamoly'] = If.predict(train)\ntrain.anamoly.value_counts()\ntrain = train[train.anamoly ==1]\ntrain.drop(columns =['anamoly'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:18.172164Z","iopub.execute_input":"2023-02-09T14:54:18.172615Z","iopub.status.idle":"2023-02-09T14:54:18.446495Z","shell.execute_reply.started":"2023-02-09T14:54:18.172576Z","shell.execute_reply":"2023-02-09T14:54:18.445074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Isolation forest to remove outliers","metadata":{}},{"cell_type":"code","source":"y = train.quality\ntrain.drop(columns = ['quality'], inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:22.599789Z","iopub.execute_input":"2023-02-09T14:54:22.600233Z","iopub.status.idle":"2023-02-09T14:54:22.607472Z","shell.execute_reply.started":"2023-02-09T14:54:22.600193Z","shell.execute_reply":"2023-02-09T14:54:22.606027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Separating features and target variable","metadata":{}},{"cell_type":"code","source":"for i in train.columns:\n    sns.boxplot(x = train[i])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boxplot to check the data symmetry","metadata":{}},{"cell_type":"code","source":"for i in train.columns:\n    sns.histplot(train[i], kde = True)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogram to check the distribution","metadata":{}},{"cell_type":"code","source":"cohen_kappa = make_scorer(cohen_kappa_score, weights = 'quadratic', greater_is_better = False)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:26.992666Z","iopub.execute_input":"2023-02-09T14:54:26.993094Z","iopub.status.idle":"2023-02-09T14:54:26.999008Z","shell.execute_reply.started":"2023-02-09T14:54:26.993058Z","shell.execute_reply":"2023-02-09T14:54:26.997428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting the scorer as cohen_kappa_scorer","metadata":{}},{"cell_type":"code","source":"def eval_model(model, param, train, y, cohen_kappa):\n    outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 0)\n    inner_cv = KFold(n_splits = 5, shuffle = True, random_state = 0)\n    random = RandomizedSearchCV(model, param, n_jobs = -1, cv= inner_cv, scoring = cohen_kappa, random_state = 0)\n    scores = []\n    n_iter = random.n_iter\n    with tqdm(total = n_iter) as pbar:\n        for i in range(n_iter):\n            random.set_params(n_iter = 1)\n            for train_index, test_index in cv_outer.split(train, y):\n                trainx, testx = train.iloc[train_index], train.iloc[test_index]\n                trainy, testy = y.iloc[train_index], y.iloc[test_index]\n                random.fit(trainx, trainy)\n                scores.append(random.best_estimator_.score(testx, testy))\n            pbar.update()\n    print(\"Average cohen_kappa\", np.mean(scores))\n    print(random.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:09:23.939401Z","iopub.execute_input":"2023-02-09T15:09:23.940825Z","iopub.status.idle":"2023-02-09T15:09:23.951521Z","shell.execute_reply.started":"2023-02-09T15:09:23.940773Z","shell.execute_reply":"2023-02-09T15:09:23.950208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DecisionTreeClassifier()\ncriterion = ['gini', 'entropy']\nmin_samples_split = np.array(range(2, 100))\nmax_depth = np.array(range(1, 100))\nparam = {'criterion': criterion, 'min_samples_split': min_samples_split, 'max_depth': max_depth}\neval_model(model, param, train, y, cohen_kappa)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:09:26.8747Z","iopub.execute_input":"2023-02-09T15:09:26.875414Z","iopub.status.idle":"2023-02-09T15:09:29.949439Z","shell.execute_reply.started":"2023-02-09T15:09:26.875372Z","shell.execute_reply":"2023-02-09T15:09:29.948122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree\n### Randomizedsearch with nested cv\n### Score of 0.578","metadata":{}},{"cell_type":"code","source":"model = ExtraTreesClassifier()\ncriterion = ['gini', 'entropy']\nmax_depth = np.array(range(50, 150))\nmin_samples_split = np.array(range(1, 100))\nn_estimators = np.array(range(100,300, 2))\nparam = {'criterion': criterion, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'n_estimators': n_estimators}\neval_model(model, param, train, y, cohen_kappa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extra Trees\n### Randomizedsearch with nested cv\n### Score of 0.587","metadata":{}},{"cell_type":"code","source":"model = BaggingClassifier()\nn_estimators = np.array(range(100,300,2))\nmax_features = np.array(range(1,12))\nparam = {'n_estimators': n_estimators, 'max_features': max_features}\neval_model(model, param, train, y, cohen_kappa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bagging Classifier\n### Randomizedsearch with nested cv\n### Score of 0.579","metadata":{}},{"cell_type":"code","source":"model = AdaBoostClassifier()\nn_estimators = np.array(range(100, 300, 2))\nlearning_rate = np.array(range(1, 20))\nparam = {'n_estimators': n_estimators, 'learning_rate': learning_rate}\neval_model(model, param, train, y, cohen_kappa)      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ada Boost\n### Randomizedsearch with nested cv\n### Score of 0.316","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ntransformy = pd.DataFrame(le.fit_transform(y.values.ravel()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(objective='multi:softmax',\n                     eval_metric='mlogloss', num_class = 6)\nlearning_rate = np.linspace(0.01, 0.3, 10)\neta = np.linspace(0.01, 0.3, 10)\ngamma = np.linspace(0, 1, 10)\nmax_depth = np.array(range(1, 10))\nalpha= np.array(range(0, 50))\nreg_lambda = np.linspace(0, 100, 10)\ncolsample_bytree = np.linspace(0.1,1, 10)\nsubsample = np.linspace(0.1, 1, 10)\nmin_child_weight = np.array(range(0,100,10))\nn_estimators = np.array(range(200, 2000,100 ))\nparam = {'learning_rate': learning_rate, 'eta': eta, 'gamma': gamma, 'max_depth': max_depth, 'alpha': alpha,'reg_lambda': reg_lambda,\n        'colsample_bytree': colsample_bytree, 'subsample': subsample, 'min_child_weight': min_child_weight, 'n_estimators': n_estimators}\ncv_outer = KFold(n_splits = 5, shuffle = True, random_state = 0)\ncv_inner = KFold(n_splits = 5, shuffle = True, random_state = 0)\nscores = []\nrxgb = RandomizedSearchCV(model, param, cv = cv_inner, n_jobs = -1, scoring = cohen_kappa)\nn_iter = rxgb.n_iter\nwith tqdm(total = n_iter) as pbar:\n    for i in range(n_iter):\n        rxgb.set_params(n_iter = 1)\n        for train_index, test_index in cv_outer.split(train, transformy):\n            trainx, testx = train.iloc[train_index], train.iloc[test_index]\n            trainy, testy = transformy.iloc[train_index], transformy.iloc[test_index]\n            rxgb.fit(trainx, trainy)\n            predy = rxgb.best_estimator_.predict(testx)\n            scores.append(cohen_kappa_score(testy, predy))\n        pbar.update()\nprint('Average score', np.mean(scores))\nprint(rxgb.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:54:41.733243Z","iopub.execute_input":"2023-02-09T14:54:41.733695Z","iopub.status.idle":"2023-02-09T14:54:41.803395Z","shell.execute_reply.started":"2023-02-09T14:54:41.733655Z","shell.execute_reply":"2023-02-09T14:54:41.801593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(subsample = 0.4, reg_lambda = 44.44, n_estimators = 1200, min_child_weight = 50, max_depth = 8, learning_rate =0.1366, gamma = 0.4444, eta= 0.04222, colsample_bytree = 0.4, alpha = 44, random_state = 0)\nmodel.fit(trainx, trainy)\npredictions = model.predict(test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = le.inverse_transform(predictions)\npredictions = pd.DataFrame(predictions, index = test.index, columns =['quality'])\npredictions.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGB Boost\n### Randomizedsearch with nested cv\n### Score of 0.17","metadata":{}},{"cell_type":"code","source":"level_0_estimators = dict()\nlevel_0_estimators[\"logreg\"] = LogisticRegression(max_iter = 100000, random_state = 100)\nlevel_0_estimators[\"forest\"] = model = RandomForestClassifier(criterion = 'gini', min_samples_split = 42, max_depth = 41, n_estimators=75, random_state = 100)\n \nlevel_0_columns = [f\"{name}_prediction\" for name in level_0_estimators.keys()]\n \nlevel_1_estimator =  RandomForestClassifier(n_estimators = 140, min_samples_split = 23, max_depth = 81, criterion = 'gini', random_state = 100)\nkfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 100)\nmodel = StackingClassifier(estimators=list(level_0_estimators.items()), \n                                    final_estimator=level_1_estimator, \n                                    passthrough=True, cv=kfold, stack_method=\"predict_proba\")\n\nmodel.fit(trainx, trainy.values.ravel())\npredy = model.predict(testx)\nprint('score',cohen_kappa_score(testy,  predy, weights = \"quadratic\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking Classifier\n### Randomizedsearch with nested cv\n### Score of 0.49","metadata":{}},{"cell_type":"code","source":"model = LGBMClassifier()\nlearning_rate = np.linspace(0.01, 0.2, 10)\nmax_depth = np.array(range(1, 10))\nalpha= np.array(range(0, 50))\nreg_lambda = np.linspace(0, 100, 10)\ncolsample_bytree = np.linspace(0.1,1, 10)\nsubsample = np.linspace(0.1, 1, 10)\nsubsample_freq = np.array(range(1, 10, 10))\nmin_child_samples  = np.array(range(1,50,10))\nn_estimators = np.array(range(200, 2000,100 ))\nnum_leaves =np.array(range(2, 200, 11))\nparam = {'learning_rate': learning_rate, 'max_depth': max_depth, 'alpha': alpha, 'reg_lambda': reg_lambda, 'colsample_bytree': colsample_bytree,\n        'subsample': subsample, 'subsample_freq': subsample_freq, 'min_child_samples': min_child_samples, 'n_estimators': n_estimators,\n        'num_leaves': num_leaves}\ncv_inner = KFold(n_splits = 5, shuffle = True, random_state = 0)\ncv_outer = KFold(n_splits = 5, shuffle = True, random_state = 0)\nscores = []\nrlgbm = RandomizedSearchCV(model, param, cv= cv_inner, scoring = cohen_kappa, n_jobs = -1, random_state = 0)\nn_iter = rlgbm.n_iter\nwith tqdm(total = n_iter) as pbar:\n    for i in range(n_iter):\n        rlgbm.set_params(n_iter = 1)\n        for train_index, test_index in cv_outer.split(train, y):\n            trainx, testx = train.iloc[train_index], train.iloc[test_index]\n            trainy, testy = y.iloc[train_index], y.iloc[test_index]\n            rlgbm.fit(trainx, trainy.values.ravel())\n            predy = rlgbm.best_estimator_.predict(testx)\n            scores.append(cohen_kappa_score(testy, predy))\n        pbar.update()\nprint('Average Score', np.mean(scores))\nprint(rlgbm.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:10:36.945451Z","iopub.execute_input":"2023-02-09T15:10:36.945936Z","iopub.status.idle":"2023-02-09T15:10:49.132958Z","shell.execute_reply.started":"2023-02-09T15:10:36.945895Z","shell.execute_reply":"2023-02-09T15:10:49.131253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBM\n### Randomizedsearch with nested cv\n### Score of 0.245","metadata":{}},{"cell_type":"code","source":"model = LGBMClassifier(subsample_freq = 1, subsample = 1, reg_lambda = 33.33 ,  num_leaves = 68, n_estimators = 1800, min_child_samples = 21, max_depth = 4, learning_rate = 0.136, colsample_bytree = 0.5, alpha = 17,  random_state = 0)\nmodel.fit(trainx,trainy.values.ravel())\npredictions = pd.DataFrame(model.predict(test), index = test.index, columns =['quality'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier()\ncriterion = ['entropy', 'gini']\nmax_depth = np.array(range(1, 100))\nmin_samples_split= np.array(range(1, 100))\nn_estimators = np.array(range(100,300,2))\nparam = {'criterion': criterion, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'n_estimators': n_estimators}\neval_model(model, param, train, y, cohen_kappa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The best model\n### Random Forest\n### Randomizedsearch with nested cv\n### Score of 0.590","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators = 122, min_samples_split = 88, max_depth = 31, criterion = 'entropy', random_state = 0)\nmodel.fit(trainx,trainy.values.ravel())\npredictions = pd.DataFrame(model.predict(test), index = test.index, columns =['quality'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}